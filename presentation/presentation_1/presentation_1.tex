%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Beamer Presentation
% LaTeX Template
% Version 1.0 (10/11/12)
%
% This template has been downloaded from:
% http://www.LaTeXTemplates.com
%
% License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND THEMES
%----------------------------------------------------------------------------------------

\documentclass{beamer}

\mode<presentation> {

% The Beamer class comes with a number of default slide themes
% which change the colors and layouts of slides. Below this is a list
% of all the themes, uncomment each in turn to see what they look like.

%\usetheme{default}
%\usetheme{AnnArbor}
%\usetheme{Antibes}
%\usetheme{Bergen}
%\usetheme{Berkeley}
%\usetheme{Berlin}
%\usetheme{Boadilla}
%\usetheme{CambridgeUS}
%\usetheme{Copenhagen}
%\usetheme{Darmstadt}
%\usetheme{Dresden}
%\usetheme{Frankfurt}
%\usetheme{Goettingen}
%\usetheme{Hannover}
%\usetheme{Ilmenau}
%\usetheme{JuanLesPins}
%\usetheme{Luebeck}
\usetheme{Madrid}
%\usetheme{Malmoe}
%\usetheme{Marburg}
%\usetheme{Montpellier}
%\usetheme{PaloAlto}
%\usetheme{Pittsburgh}
%\usetheme{Rochester}
%\usetheme{Singapore}
%\usetheme{Szeged}
%\usetheme{Warsaw}

% As well as themes, the Beamer class has a number of color themes
% for any slide theme. Uncomment each of these in turn to see how it
% changes the colors of your current slide theme.

%\usecolortheme{albatross}
%\usecolortheme{beaver}
%\usecolortheme{beetle}
%\usecolortheme{crane}
%\usecolortheme{dolphin}
%\usecolortheme{dove}
%\usecolortheme{fly}
%\usecolortheme{lily}
%\usecolortheme{orchid}
%\usecolortheme{rose}
%\usecolortheme{seagull}
%\usecolortheme{seahorse}
%\usecolortheme{whale}
%\usecolortheme{wolverine}

%\setbeamertemplate{footline} % To remove the footer line in all slides uncomment this line
%\setbeamertemplate{footline}[page number] % To replace the footer line in all slides with a simple slide count uncomment this line

%\setbeamertemplate{navigation symbols}{} % To remove the navigation symbols from the bottom of all slides uncomment this line
}

\usepackage{todonotes}
\usepackage{graphicx} % Allows including images
\usepackage{booktabs} % Allows the use of \toprule, \midrule and \bottomrule in tables
\usepackage{pgfplots}
\usepgfplotslibrary{external}


%----------------------------------------------------------------------------------------
%	TITLE PAGE
%----------------------------------------------------------------------------------------

\title[BKG]{Building Knowledge Graphs} % The short title appears at the bottom of every slide, the full title is only on the title page

\author[Data Science]{Lukas Bl{\"u}baum \\ Nick D{\"u}sterhus \\ Monika Werner} % Your name
\institute[UPB] % Your institution as it will appear on the bottom of every slide, may be shorthand to save space
{
University of Paderborn \\ % Your institution for the title page
\medskip
\textit{https://github.com/LukasBluebaum/BKG} % Your email address
}
\date{July 19, 2018} % Date, can be changed to a custom date

\begin{document}

\begin{frame}
\titlepage % Print the title page as the first slide
\end{frame}

\begin{frame}
\frametitle{Overview} % Table of contents slide, comment this block out to remove it
\tableofcontents % Throughout your presentation, if you choose to use \section{} and \subsection{} commands, these will automatically be printed on this slide as an overview of your presentation
\end{frame}

%----------------------------------------------------------------------------------------
%	PRESENTATION SLIDES
%----------------------------------------------------------------------------------------

%------------------------------------------------
\section{Preprocessing (Cleaning and Coreference Resolution)} % Sections can be created in order to organize your presentation into discrete blocks, all sections and subsections are automatically printed in the table of contents as an overview of the talk
%------------------------------------------------

\begin{frame}
\frametitle{Extraction and cleaning of text from Wikipedia Dump}
\begin{block}{Foundation}
	Wikipedia dump consisting of plain text without markup, infoboxes or chapter subdivision 
\end{block}
\begin{itemize}
	\item Using regular expressions to remove unnecessary URLs, parentheses, whitespace, null char, symbols
	\item WikiCleaner class using Writer and Reader Threads for faster cleaning
\end{itemize}
\end{frame}

%------------------------------------------------

%------------------------------------------------

\begin{frame}
\frametitle{Extraction and cleaning of text from Wikipedia Dump}
\begin{columns}[c] % The "c" option specifies centered vertical alignment while the "t" option is used for top vertical alignment

\column{.5\textwidth} % Left column and width
\includegraphics[scale=0.35]{Worker.PNG}

\column{.5\textwidth} % Right column and width
\includegraphics[scale=0.4]{WikiCleaner.PNG}

\end{columns}
\end{frame}

\begin{frame}
\frametitle{Coreference Resolution}
\begin{itemize}
	\item Stanford NLP CoreRef to find the representative mention
	\item Replace pronouns and possessive pronouns
\end{itemize}
\begin{example}[]
	\begin{itemize}
		\item John met Judy in 1960. He married her during his college year.
		\item[] $\Rightarrow$ John met Judy in 1960. John married Judy during John's college year.
	\end{itemize}
\end{example}
\end{frame}

%------------------------------------------------


%------------------------------------------------
\section{Named Entity Recognition}
%------------------------------------------------

\begin{frame}
\frametitle{Named Entity Recognition}
\begin{columns}[c]
\column{.5\textwidth} % Left column and width
\begin{itemize}
	\item Requesting Spotlight Demo and parsing JSON response to Entity class
\end{itemize}
\column{.5\textwidth} % Left column and width	
\includegraphics[scale=0.4]{Entity.PNG}
\end{columns}
\end{frame}

%------------------------------------------------

%------------------------------------------------
\section{Entity Disambiguation}
%------------------------------------------------

\begin{frame}
\frametitle{Entity Disambiguation}
\begin{block}{Frameworks}
\begin{itemize}
	\item Spotlight: Integrated disambiguation with two approaches: 
	\begin{itemize}
		\item The information (context) next to a candidate's surface forms is used to find the most likely disambiguation. The best match determines the selection.
		\item Weigh words on their ability to disambiguate between the resources
	\end{itemize}
	\item[] \cite{p2}
	\item Fox: AGDISTIS
\end{itemize}
\end{block}
\begin{itemize}
	\item[] $\Rightarrow$ Done by given frameworks
\end{itemize}

\end{frame}

%------------------------------------------------

%------------------------------------------------
\section{Relation Extraction}
%------------------------------------------------

\begin{frame}
\frametitle{Relation Extraction}
\begin{itemize}
	\item Two ways of extracting relations:
	\begin{itemize}
		\item Fox in 're' mode, performing entity recognition as well as relation extraction
		\begin{itemize}
			\item Saving triple statements
		\end{itemize}
		\item Our RelationExtraction method using OpenIE and Spotlight 
	\end{itemize}
\end{itemize}
\end{frame}

%------------------------------------------------



\begin{frame}
\frametitle{Relation Extraction: Own Approach}
\begin{itemize}
	\item Parsing ontology and creating a list of properties
	\item Write these to a JSON-File 
	\begin{itemize}
		\item Can then be edited manually or automatically
	\end{itemize}
	\item Using Spotlight for NER, so we can run it concurrent to FOX
	\item Using Stanford CoreNLP 
	\begin{itemize}
		\item Experimented with different approaches to find relations given two entities (search algorithms on dependency trees, semanticGraph)
		\item Decided to use OpenIE
	\end{itemize}
\end{itemize}
\end{frame}

%------------------------------------------------

\begin{frame}
\frametitle{Relation Extraction: OpenIE }
\begin{itemize}
	\item Splitting sentences into shorter fragments, appeal to natural logic to maintain context
	\item Traverse dependency tree recursively \cite{p1}
	\item Disadvantage in our case: have to filter for entity to entity relations 
	\item After finding the binary relation (OpenIE Triple) between entities: Map them to DBpedia ontology
\end{itemize}
\end{frame}

%------------------------------------------------

\begin{frame}
\frametitle{Relation Extraction: OpenIE }
\begin{itemize}
	\item Parse DBpedia properties to Java objects
	\item Search for a valid property (check domain and range)
	\item Map relation to keywords to find proper property 
	\begin{itemize}
		\item If a keyword String consists of multiple words
		\item[] $\Rightarrow$ All words have to be found to map a relation to the property
		\item Work with lemmatization
	\end{itemize}
	\item Also searches for numbers to find entity to literal relations
	\item Write triple to graph
\end{itemize}
\end{frame}

%------------------------------------------------
\begin{frame}
\frametitle{Relation Extraction 1.1 }
\begin{example}[]
	\begin{itemize}
		\item \textit{Multiple Sentences (as many as Spotlight can handle):} \\
		\begin{itemize} \item Obama was born on August 4, 1961, at Kapiolani Medical Center for Women and Children in Honolulu, Hawaii. He graduated from Harvard University.
		\end{itemize}
		\item Coreference Resolution:  \begin{itemize} \item Obama was born on August 4 , 1961 , at Kapiolani Medical Center for Women and Children in Honolulu , Hawaii . Obama graduated from Harvard University. 
		\end{itemize}
		\item Binary Relation Extraction:  \begin{itemize} \item First sentence: Obama - be bear on - August 4 1961. (among others)
			\item Second sentence: Obama - graduate from - Harvard University (among others)
		\end{itemize}	 
	\end{itemize}
\end{example}
\end{frame}
%------------------------------------------------
\begin{frame}
\frametitle{Relation Extraction 1.2 - Entity to Literal Relation}
\begin{example}
\begin{itemize}
	\item \textit{Named Entity Recognition and mapping surface form back to sentences} \\
	\begin{itemize} \item \underline{Obama} was born on August 4, 1961, at \underline{Kapiolani} Medical Center for Women and Children in \underline{Honolulu}, \underline{Hawaii}. \underline{Obama} graduated from \underline{Harvard University} .
	\end{itemize}
	\item Entity to literal extraction: Obama - be bear on - August 4 1961. \begin{itemize} \item Search for entity in subject of the binary relations \\ $\Rightarrow$ Obama (Types: Person, ...) 
		\item Search for literal in object: $\Rightarrow$ detects numbers 
		\item Search if object contains a date if not extract single literal: \\ $\Rightarrow$ detects month + numbers (date found)
		\item Convert to date format: $\Rightarrow$  1961-08-04
		\item Map relation to property: keyword: bear  $\Rightarrow$ dbo:birthDate \\ (Domain: Person - Range: xsd:date)
		\item Write dbo:Barack\_Obama dbo:birthDate "1961-08-04"\textasciicircum{}\textasciicircum{}xsd:date to graph
	\end{itemize}		 
\end{itemize}
\end{example}
\end{frame}
\begin{frame}
\frametitle{Relation Extraction 1.3 - Entity to Entity Relation}
\begin{example}
\begin{itemize}
\item \textit{Named Entity Recognition and mapping surface form back to sentences} \\
\begin{itemize} \item \underline{Obama} was born on August 4, 1961, at \underline{Kapiolani} Medical Center for Women and Children in \underline{Honolulu}, \underline{Hawaii}. \underline{Obama} graduated from \underline{Harvard University} .
\end{itemize}
\item Entity to entity extraction: Obama - graduate from - Harvard University \begin{itemize} \item Search for entity in subject and in object of the binary relations \\ $\Rightarrow$ Obama (Types: Person, ...), Harvard University (Type: EducationalInstitution )
	\item Iterate over all properties with given domain and range
	\item Map relation to property: \\ keyword: graduate $\Rightarrow$ dbo:almaMater
	\item Write dbo:Barack\_Obama dbo:almaMater dbo:Harvard\_University to graph
\end{itemize}		 

\end{itemize}
\end{example}
\end{frame}


%------------------------------------------------
\section{Architecture}
%------------------------------------------------

\begin{frame}
\frametitle{Architecture}
\begin{center}
	\includegraphics[scale=0.43]{architecture.PNG}
\end{center}
\end{frame}

%------------------------------------------------

%------------------------------------------------

%------------------------------------------------
\section{Benchmark}
%------------------------------------------------
\begin{frame}
\frametitle{Benchmark}
\begin{itemize}
	\item Benchmark class: Given a category and one or more dumps
	\item Querying for all subjects of the given category
	\item Can merge multiple n-triple dumps into one file to load it in memory
	\item Counts and compares all relations with a subject of the given category for the model and dumps
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Benchmarking our result}

\begin{block}{Approach}
	\begin{itemize}
		\item Selected category: \textbf{Presidents of the United States}
		\item Compared our result with the given dumps 
		\item Selected 100 triples randomly that were not contained in the dumps and checked them manually
		\item Only used our relation extraction approach for the benchmarking
	\end{itemize}
\end{block}

\end{frame}


\begin{frame}
\frametitle{Result}
\begin{itemize}
	\item From the 2810 triples contained in the dumps we also found 556 
	\item Out of the 100 randomly sampled triples 46 were correct.
	\item[] $\Rightarrow$ Recall = 0.197
	\item[] $\Rightarrow$ Precision = 0.46
	\item[] $\Rightarrow$ F-measure = 0.27
\end{itemize}

\end{frame}

\begin{frame}
\frametitle{Runtime}
\begin{tikzpicture}
\begin{axis}[%
scale only axis,
width=4in,
height=2.6in,
xlabel=Length in characters,
ylabel= Time in minutes,
xmin=0, xmax=120000,
ymin=0, ymax=8,
axis on top]
\addplot[
ybar,
bar width=0.0502874in, 
bar shift=0in,
fill=blue!40,
draw=black] 
plot coordinates{ 
	(111453,3.3666666666666667) (94918,4.116666666666666) (85842,3.95) (85233,2.716666666666667) (50916,1.3166666666666667) (119839,4.466666666666667) (97655,2.6333333333333333) (95166,2.7333333333333334) (75964,7.05) (77587,3.7) (58296,3.716666666666667) (58807,5.55) (75869,6.35) (65114,1.8666666666666667) (87427,3.283333333333333) (57004,1.5666666666666667) (46195,1.9333333333333333) (104960,3.433333333333333) (89576,2.35) (102306,3.1333333333333333) (104061,2.85) (107992,2.716666666666667) (93254,2.25) (88178,4.783333333333333) (76518,3.3666666666666667) (118674,4.25) (48980,3.533333333333333) (74002,1.9666666666666666) (112234,3.316666666666667) (92795,3.8)
	(103164,3.0) (80339,2.216666666666667) (86315,3.8333333333333335) (111862,3.533333333333333) (56341,1.5166666666666666) (106587,6.816666666666666) (59495,4.033333333333333) (50342,1.45) (64839,1.9166666666666667) (53873,1.6666666666666667) (68984,2.1) (42456,1.1833333333333333) (71311,2.066666666666667) (97937,2.816666666666667) (3766,0.1) (9602,0.55) (53799,1.2666666666666666) (43464,1.4) (17488,0.48333333333333334) (12635,0.4166666666666667)  (84084,2.3666666666666667) (2444,0.08333333333333333) (2409,0.03333333333333333) (7190,0.16666666666666666) (33914,1.0) (43369,1.0166666666666666) (3174,0.18333333333333332) (75744,2.4166666666666665)
	(66070,1.6) (42017,0.9666666666666667) (5942,0.06666666666666667) (28364,0.6166666666666667) (9997,0.5166666666666667) (2238,1.2333333333333334) (5458,0.11666666666666667) (51101,1.3333333333333333) (1642,0.31666666666666665) (19755,0.4666666666666667) (29098,0.6166666666666667) (50725,1.2833333333333334) (16995,0.55) (19289,0.4666666666666667) (43271,1.2333333333333334) (7043,0.18333333333333332) (6724,0.5666666666666667) (44063,3.9166666666666665) (40813,1.5333333333333334) (111453,3.066666666666667) (72158,1.5333333333333334) (84186,2.3833333333333333) (27028,1.2833333333333334) (71598,2.6) (57741,1.7333333333333334) (39596,1.1) (30098,0.8) (1648,0.03333333333333333)
};

\end{axis}
\end{tikzpicture}
\end{frame}

\begin{frame}
\frametitle{Runtime}
\begin{itemize}
	\item Approximately 70-80\% of the runtime is the Stanford Coref-Annotator
	\item Initial runtime due to loading of the models neglected (only once at the start)
\end{itemize}

\end{frame}

%------------------------------------------------
\section{Discussion}
%------------------------------------------------
\begin{frame}
\frametitle{Discussion}
\begin{itemize}
	\item Many information can only be found in the infoboxes (Example: height)
	\item Missing triples due to false disambiguations (Example: History of some party)
	\item Disambiguations can change depending on the amount of text
	\item Main difficulty - mapping of properties:
	\begin{itemize}
		\item We miss context on properties that lack domain and/or range
		\item Huge number of carefully selected keywords are needed (Example: appointer as keyword leads to the inverse of the expected result)		
	\end{itemize}

\end{itemize}

\end{frame}


\begin{frame}
\frametitle{References}
\footnotesize{
	\begin{thebibliography}{99} % Beamer does not support BibTeX so references must be inserted manually as below
		\bibitem[Mendes, Jakob, García-Silva, Bizer, 2011]{p2} Pablo N. Mendes, Max Jakob, Andrés García-Silva and Christian Bizer (2011)
		\newblock DBpedia Spotlight: Shedding Light on the Web of
		Documents
		\newblock \emph{
			Proceedings of the 7th International Conference on Semantic Systems (I-Semantics) } 3.
	\end{thebibliography}
	\begin{thebibliography}{99} % Beamer does not support BibTeX so references must be inserted manually as below
		\bibitem[Angeli, Premkumar, Manning, 2015]{p1} Gabor Angeli, Melvin Johnson Premkumar, and Christopher D. Manning (2015)
		\newblock Leveraging Linguistic Structure For Open Domain Information
		Extraction
		\newblock \emph{
			In Proceedings of the Association of Computational Linguistics (ACL) } 2.
	\end{thebibliography}
}
\end{frame}


\end{document} 
